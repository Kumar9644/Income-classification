# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gPSC1f6N3H5hwe6Tp_vBqtYHIITRodzL
"""

import pandas as pd
import numpy as np
import seaborn as sns 
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import LabelEncoder,MinMaxScaler,OneHotEncoder,StandardScaler
from sklearn.linear_model import  LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.compose import ColumnTransformer
from sklearn.metrics import *
from sklearn.svm import SVC

df=pd.read_csv('data_new.csv')
df.head()

df_temp=df.apply(lambda x:x.str.strip() if x.dtype=='O' else x)

df_temp['workclass']=df_temp['workclass'].apply(lambda x:np.nan if x=='?' else x)

df_temp['occupation']=df_temp['occupation'].apply(lambda x:np.nan if x=='?' else x)

df_temp.dropna(inplace=True)

df_temp.isnull().sum()

df_temp.dropna(inplace=True)

sns.distplot(df['capital_gain'])

df.describe()

plt.figure(figsize=(10,6))
sns.countplot(df_temp['workclass'])

df_temp['occupation'].value_counts()

df['target'].value_counts()

df_temp['workclass'].value_counts()

sns.distplot(df_temp['capital_loss'])

df_temp['marital_status'].value_counts()

df_temp['sex'].value_counts()

df_temp.drop('naive_country',axis=1,inplace=True)

df_temp.drop('education',axis=1,inplace=True)

df_temp.drop('marital_status',axis=1,inplace=True)

df_temp.drop(['race','sex','relationship'],axis=1,inplace=True)

df_temp.shape



df_new=df_temp[(df_temp['capital_loss']<500) & (df_temp['capital_gain']<20000)]

df_new=df_new.drop(df_new[df_new['target']=='>5'].index)

df_new.shape

x_train['capital_loss'].hist()

x_train['capital_gain'].hist()

X=df_new.drop('target',axis=1)
y=df_new.target

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

cat_cols=[i for i in x_train.columns if x_train[i].dtype=='O']
num_cols=[i for i in x_train.columns if x_train[i].dtype!='O']

label=LabelEncoder()
for i in cat_cols:
  x_train[i]=label.fit_transform(x_train[i])
  x_test[i]=label.transform(x_test[i])

# ct=ColumnTransformer([
#                       ('step1',OneHotEncoder(sparse=False,handle_unknown='ignore'),cat_cols),
#                       # ('step2',StandardScaler(),num_cols)
# ])

pp=Pipeline([
             ('step2',MinMaxScaler()),
            #  ('model',SVC())
            ('model',LogisticRegression(C=100,solver='newton-cg',max_iter=400))
])

y_pred=pp.fit(x_train,y_train).predict(x_test)
accuracy_score(y_test,y_pred)

print(classification_report(y_test,y_pred))

print(confusion_matrix(y_test,y_pred))

from sklearn.model_selection import GridSearchCV
param={
    'model__C':[100,10,0.1,0.01],
    'model__solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']

}

gvc=GridSearchCV(pp,param_grid=param,scoring='accuracy')
gvc.fit(x_train,y_train)

gvc.best_params_







